{
  
    
        "post0": {
            "title": "What I Want From The Advent of Code",
            "content": "I learned about Advent of Code (AoC) for the first time back when I was first learning to program. I’m a self-taught guy, insofar as such a thing exists, and it seemed like a neat thing. The trouble is, the problems are hard! I was nowhere near ready to tackle them back then. . Fast-forward to now. I’m actually a working developer, with several years of experience on the job! I worked for years to learn, and built up the ability to be gainfully employed in the field of web-development. It seemed to me like I should be a little more prepared to take a whack at the AoC challenges! . Nope. Not at all. . I believe that there are two kinds of knowledge: . The things that you know because you have “learned” them | The things that you know because you have experienced them | In an ideal world, schooling would include both. But once you get out into the world, sometimes you don’t have time for one or the other. I put “learned” in quotes because there’s not a word that comes to mind for what I’m trying to say. In this case I guess I mean something like, “You have studied it theoretically. Perhaps read about it, and you have done so sufficiently to produce a lasting awareness.” I think that in most cases people mean “learn” to be both steps. Except when they don’t. Language is, after all, a somewhat messy set of abstractions. . But I digress. Early on in the process of interviewing I read a lot of posts in various media about the disconnect between these types of problems and what you actually deal with on the job. My current experience with AoC is me taking the second step. . I very rarely need to be concerned with what algorithm there is for traversing a graph efficiently. More often than not that sort of thing is either implemented already, or is outside of the scope of my domain. Keeping in mind that I work in web-development as a full-stack engineer, what I usually have to deal with is more banal. I am much more likely to have to pick a dependency than a sorting algorithm. . But there’s another side of that which I also read about: you don’t need to know it until you do, and if you don’t, then your solution is going to be garbage. . This is going to be a lot of the same for anyone who spends a lot of time reading technical blogs. Also, is anyone actually reading this? I dunno. But sometimes you do run across hard problems. Sometimes, whether through some contraint of the work environment (that dependency’s license isn’t allowed) or the logic required (we need it to be almost that but this edge case in the business logic breaks the dependency), you can’t use an existing solution. That’s when knowing, and I mean really knowing these problems and their solutions will shine. . You might be able to see through a tree traversal problem that is hiding under the hood of an HTML rendering issue. Or perhaps you’ll see the topological sort in an attempt to organize various YAML files. Because it’s so niche, and so much a part of the application’s nuance, there is no solution besides what you can build. . When I started to try and do a post for each day of the AoC this year, I thought I could keep up; and I did for a little while. But then I hit a problem that I truly didn’t know how to solve. Then I hit a problem that I knew how to solve, but only in the naive way. Then I hit another, and another, and another that I just. couldn’t. solve. . So, while my original goal is not achievable, I want to keep going. I think that there is value in pushing yourself to learn these things. But more than that, I think that there is value in learning to fail, and push forward with altered expectations. That’s what I want to get from AoC this year. The feeling of succeeding after failure. .",
            "url": "https://pcapel.github.io/thoughts-and-things/advent-of-code%20stream-of-consciousness/2021/12/29/what-i-want-from-aoc.html",
            "relUrl": "/advent-of-code%20stream-of-consciousness/2021/12/29/what-i-want-from-aoc.html",
            "date": " • Dec 29, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Advent of Code 2021 - Day 3",
            "content": "Day 3 . On the third day of AoC my data gave to me... a long list of binary. . Part 1 . This problem is to use a list of binary to generate two binary numbers, then multiply them. That means that this could be done without converting the list to actual binary, though there&#39;s probably a clever way to get the answer if we do. . The first number is composed of the most common bit from each position. So if we have: . 1011 0010 0110 . Then we would build the number 0010, since those are the most common bits in each column position. The second number is made from the least common bit, which just means that we flip the bits of the first and boom, we have it. . With that said, let&#39;s build a simple solution: . with open(&#39;../assets/inputs/aoc/2021/day_3.txt&#39;, &#39;r&#39;) as data_file: lines = [line.strip() for line in data_file.readlines()] display(lines[:3], lines[997:]) . [&#39;001001100101&#39;, &#39;010100011100&#39;, &#39;100000110001&#39;] . [&#39;011000110110&#39;, &#39;101110011011&#39;, &#39;110101100001&#39;] . side note: I don&#39;t think that we&#39;re going to get the opportunity to do so here, but you might be interested in trying to figure out how you could re-write any of these answers such that we aren&#39;t required to read the whole data set into memory. It&#39;s a fun challenge! . So now we have our lines, and the naive approach is just sitting there waiting for us! What we would need to do if we did this by hand is mark down a count of each bit in each position. I migth use tally marks, but since we&#39;re pythonistas we could use a collections counter. The only issue is that we want to use it on the columns. . Because the data we want is column-wise and we left the values as strings, we could just iterate the list a few times to get it. I&#39;m lazy, so I&#39;m going to do that first. . from collections import Counter elem_len = len(lines[0]) list_len = len(lines) columns = [[lines[i][j] for i in range(list_len)] for j in range(elem_len)] counts = [Counter(column) for column in columns] display(counts) . [Counter({&#39;0&#39;: 528, &#39;1&#39;: 472}), Counter({&#39;0&#39;: 479, &#39;1&#39;: 521}), Counter({&#39;1&#39;: 485, &#39;0&#39;: 515}), Counter({&#39;0&#39;: 499, &#39;1&#39;: 501}), Counter({&#39;0&#39;: 495, &#39;1&#39;: 505}), Counter({&#39;1&#39;: 515, &#39;0&#39;: 485}), Counter({&#39;1&#39;: 512, &#39;0&#39;: 488}), Counter({&#39;0&#39;: 502, &#39;1&#39;: 498}), Counter({&#39;0&#39;: 507, &#39;1&#39;: 493}), Counter({&#39;1&#39;: 507, &#39;0&#39;: 493}), Counter({&#39;0&#39;: 504, &#39;1&#39;: 496}), Counter({&#39;1&#39;: 481, &#39;0&#39;: 519})] . Ok, we have the positional counts of each thing like we might do by hand. We just need to transform this into an actual value, or two. These will need to be multiplied, so we better make them actual binary values. Then we&#39;ll need to positionally set their bits. We could also just compute the binary value as a string and use the int function, but this method does a little bitwise operator fun that I think is interesting to try out once in a while: . powers = [2**n for n in range(elem_len - 1, -1, -1)] gamma = 0 epsilon = 0 for i, count in enumerate(counts): if count[&#39;1&#39;] &gt; count[&#39;0&#39;]: gamma |= powers[i] else: epsilon |= powers[i] display(gamma * epsilon) . 3901196 . We spin up a list of the powers of two, or each position&#39;s bit value of 1. We want to step through these in reverse order, since the puzzle considers the first bit to be the largest value. Then we use a bitwise-or on the current value, and since we start out with 0 and are moving in descending order, we know we&#39;re going to flip a 0 to a 1 for whichever number needs to be altered. . Part 1 is done! This is probably the least efficient way that I could do this, but we have an answer. . Part 2 . Part two introduces a crazy new approach. We need to parse the list down to a single number, but instead of looking at the most common bit to keep that bit, we&#39;re going to look at the most/least common bit and keep all the numbers. This process will then be applied to this new, shorter list. There are two values that we want to produce this way: og_rating and cs_rating. I picked these variables based on the fact that they&#39;re called (O)xygen (G)enerator rating and (C)O2 (S)crubber rating in the puzzle. The rules for generation are as follows: . The og_rating asks us to keep the values with a 1 in the position we&#39;re evaluating if 0 and 1 appear evenly. The cs_rating asks us to keep the values with a 0 in the position we&#39;re evaluating if 0 and 1 appear evenly. The og_rating will keep numbers whose value in the current position is the most common bit The cs_rating will keep numbers whose value in the current position is the least common bit . side note: These rules ensure that we will always shrink the list. However, it does strike me that you might be able to compose a list that doesn&#39;t get reduced to a single value in the course of applying this rule. I wonder what that might look like? What are the limits on the size of the list vs the size of it&#39;s elements such that you might be able to guarantee a value is generated? . The thing that we notice here is that the process we used before lost a lot of information. That is, my counts variable is useless for this part of the challenge. I know the most common bit, but I lost the relationship to the individual numbers in the list. Thankfully, the input here is small, so I can just iterate the numbers to create a new list based on the knowledge of what the most common things are. But then I&#39;ll need to create new positional counts. So is that really the best way? . The common problem here is to find the most common bit for a given position and a list of binary values. So we should try and do that as efficiently as possible: . def most_common_for_position(bin_values, position): zero_count = 0 ones_count = 0 for bn in bin_values: if bn[position] == &#39;0&#39;: zero_count += 1 else: ones_count += 1 if zero_count &gt; ones_count: return &#39;0&#39; elif ones_count &gt; zero_count: return &#39;1&#39; elif ones_count == zero_count: return &#39;eq&#39; . The tricky part here is that we&#39;re using 0-indexing. I find that switching to that thinking early in the process is helpful because python itself is 0-indexed. If we were using Julia, or another 1-indexed language, then we could rely on the concept. That said, problems that are one indexed in their language are always something to look out for. You know what they say, there are 2 hard problems in computer science: cache invalidation, naming things, and off-by-one errors... . At any rate, I went ahead and added an explicit case for the equality of the numbers. This will come in handy for that tie-breaker rule set. At this point it might be nice to validate our function by soliving part one again but in a different way: . def invert(str_bin): return &#39;&#39;.join([&#39;0&#39; if char == &#39;1&#39; else &#39;1&#39; for char in str_bin]) def to_num(n): return int(n, 2) gamma = &#39;&#39; for i in range(elem_len): gamma += most_common_for_position(lines, i) epsilon = invert(gamma) display(to_num(gamma) * to_num(epsilon)) . 3901196 . I would have used a binary operator for the inversion, but with signed binary numbers it was being weird. I&#39;m not used to dealing with binary, so I just opted to write a simple helper to deal with it. But we see that the function works! . At this point we have a few steps to follow: . Get the most common value for the position | Filter the list into a new list | Then we do it again, but with the position incremented. There are two ways to implement this type of logic: iterarive, and recursive. I tend to prefer iteration over recursion in python due to the stack size. I also find that things defined recursively are used easily as iterators, which are easiest to implement as iterative. So I&#39;d even implement fibonacci numbers this way. So let&#39;s get the og_rating sorted: . position = 0 binary_list = lines.copy() while len(binary_list) &gt; 1: most_common = most_common_for_position(binary_list, position) if most_common == &#39;eq&#39;: keep = &#39;1&#39; else: keep = most_common binary_list = [line for line in binary_list if line[position] == keep] position += 1 og_rating = binary_list[0] display(og_rating) . &#39;011001100111&#39; . We use essentially the same logic for the cs_rating but we insert a bit flip for the concept of &quot;least common&quot; in the cs_rating specification. Of course, doing this with actual bits would be a &quot;bit&quot; better, but we have strings, so I&#39;mma use strings. . position = 0 binary_list = lines.copy() while len(binary_list) &gt; 1: most_common = most_common_for_position(binary_list, position) if most_common == &#39;eq&#39;: keep = &#39;0&#39; else: keep = invert(most_common) binary_list = [line for line in binary_list if line[position] == keep] position += 1 cs_rating = binary_list[0] . display(to_num(og_rating) * to_num(cs_rating)) . 4412188 . Boom! There we go! . Now, this is obviously really ugly, and cleaning it up is an interesting prospect. The big issue is, we have a new list and new state related to it on every iteration. So we have to keep learning what the new most common or least common entry is for each position. If it weren&#39;t for that, we could filter the list with some globally accessible state. But alas... . What we could do is wrap the whole thing in a function, but honestly that feels ugly too. Just look at this: . def get_rating(binary_input, rating_type=&#39;og_rating&#39;): position = 0 binary_list = binary_input.copy() while len(binary_list) &gt; 1: most_common = most_common_for_position(binary_list, position) if rating_type == &#39;og_rating&#39;: if most_common == &#39;eq&#39;: keep = &#39;1&#39; else: keep = most_common else: if most_common == &#39;eq&#39;: keep = &#39;0&#39; elif most_common == &#39;1&#39;: keep = &#39;0&#39; else: keep = &#39;1&#39; binary_list = [line for line in binary_list if line[position] == keep] position += 1 return binary_list[0] display(to_num(get_rating(lines, rating_type=&#39;cs_rating&#39;)) * to_num(get_rating(lines))) . 4412188 . This is ugly. But so is what we&#39;re doing. Another option is to write the function, but give it the behavior we want by passing in a keep function. Then we remove the need for the rating_type param. . def og_rating_keep(most_common): return &#39;1&#39; if most_common == &#39;eq&#39; else most_common def cs_rating_keep(most_common): return &#39;0&#39; if most_common == &#39;eq&#39; else invert(most_common) def get_rating_hof(binary_input, keep_function): position = 0 binary_list = binary_input.copy() while len(binary_list) &gt; 1: most_common = most_common_for_position(binary_list, position) binary_list = [line for line in binary_list if line[position] == keep_function(most_common)] position += 1 return binary_list[0] display(to_num(get_rating_hof(lines, cs_rating_keep)) * to_num(get_rating_hof(lines, og_rating_keep))) . 4412188 . If you&#39;re not familiar with higher order functions, then this will be new to you. Otherwise, this is an excellent way to clean up logic that you want to know at call time. The hallmark for this is passing in a logical flag. Anytime that you do that, you could be using a higher order function. Some people might term this a &quot;callback&quot;, but that&#39;s the function that is given to a higher order function. . At any rate, this is probably the furthest I would go in trying to clean this up. We could go a step further though... . We could try and generalize the filtering. What that means is that we have some rule that we want to apply to each successive iteration of the list itself. That might look something like this: . def apply_iterative_rule(some_list, rule): list_copy = some_list.copy() iteration = 0 while len(list_copy) &gt; 1: list_copy = rule(list_copy, iteration) return list_copy[0] . What we&#39;re defining here is the interface for the rule function. We know that to apply our current rule we need the current list state (list_copy) and the position. But position is the same as iteration, and iteration is more general. . The next challenge is to come up with the rule function itself. It should basically look like the inside of our loop. After all, that&#39;s where it&#39;s being called essentially. . def rating_rule(binary_list, position): most_common = most_common_for_position(binary_list, position) return [line for line in binary_list if line[position] == keep_function(most_common)] . This is close, but we don&#39;t have the keep function, and in the context of this function, we don&#39;t control the call site. That&#39;s internal to apply_iterative_rule. If we were to change that to allow us to pass in a keep function, we&#39;d kind of break the generality. A little bit of curry could help the situation. . from functools import partial def rule_base(keep_function, binary_list, position): most_common = most_common_for_position(binary_list, position) return [line for line in binary_list if line[position] == keep_function(most_common)] og_rating_rule = partial(rule_base, og_rating_keep) cs_rating_rule = partial(rule_base, cs_rating_keep) . Using partial allows us to apply a function argument, but instead of erroring out if there are missing arguments, it just returns a callable object that will apply arguments to the original function definition. Let&#39;s see how this works: . from functools import partial def rule_base(keep_function, binary_list, position): most_common = most_common_for_position(binary_list, position) return [line for line in binary_list if line[position] == keep_function(most_common)] og_rating_rule = partial(rule_base, og_rating_keep) cs_rating_rule = partial(rule_base, cs_rating_keep) def apply_iterative_rule(some_list, rule): list_copy = some_list.copy() iteration = 0 while len(list_copy) &gt; 1: list_copy = rule(list_copy, iteration) iteration += 1 return list_copy[0] display(to_num(apply_iterative_rule(lines, og_rating_rule)) * to_num(apply_iterative_rule(lines, cs_rating_rule))) . 4412188 . Ok, so this looks really nice, but what immediately jumps out to me is that apply_iterative_rule depends on the rule actually reducing the list to a given value. That is, we can pass a perfectly operational rule to the function, and it will simply never terminate. . How could we avoid this? The simplest way I can think is to pass in a limit to the function. Something like: . def apply_iterative_rule(ls, rule, limit): ls_copy = ls.copy() iteration = 0 while len(ls_copy) &gt; limit: ls_copy = rule(list_copy, iteration) iteration += 1 return ls_copy[0] . This allows us to pass in the rule, and some expectation about it. But is there actually any guarantee that we&#39;ll terminate? It depends on the rule. Since the rule itself is decoupled from this, it feels risky to me. Essentially, we need a way to guarantee that all the rules that we pass in will decrease... . I don&#39;t really know how one might do that. This is why I prefer stopping at the prior step. We generalized just enough to clean up the code and isolate the &quot;business logic&quot; of which thing we wanted to keep. We also kept the filtration logic visible within the loop that controls it. That means that we can, just by looking at the get_rating_hof function, be relatively sure that we&#39;ll terminate. . Conclusion . This was a fun one. It gave me a chance to use partials again, and I&#39;m a huge fan of higher order functions. It feels like there may be a more general solution, but we will always sacrifice efficiency. On that note, it also seems like there is probably a pretty clever way to solve this in a super efficient way using some evil bit-level hacking. I don&#39;t generally go in for that. The code solves the problem, and it does so quickly enough for me to write it up. . I will, however, come back to the topic of termination. I feel like looking at the rules we&#39;re applying vs the input we take in is interesting enough to warrant that. As it is, our solution seems to depend on the fact that we&#39;re playing a game that must have a solution. In the real world, being able to tell if the data won&#39;t terminate is pretty valuable. I&#39;ll try to remember to update with a link to that when the time comes. .",
            "url": "https://pcapel.github.io/thoughts-and-things/advent-of-code/2021/12/03/advent-of-code-3.html",
            "relUrl": "/advent-of-code/2021/12/03/advent-of-code-3.html",
            "date": " • Dec 3, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Advent of Code 2021 - Day 2",
            "content": "Day 2! . Technically, I wrote this the same day as day 1, and on the third day release... but you can forgive that, right? . Part 1 . Anyway, we&#39;re on to day 2! This challenge centers around calculating positions. So our input is a list of directions, and values to apply to those directions. First things first, we&#39;re going to want to split those up into something meaningful. Personally, I love a good namedtuple: . from collections import namedtuple Movement = namedtuple(&#39;Movement&#39;, [&#39;direction&#39;, &#39;value&#39;]) . So each instance in the input list can now be instantiated as a Movement, so let&#39;s read in that data! . with open(&#39;../assets/inputs/aoc/2021/day_2.txt&#39;, &#39;r&#39;) as data_file: lines = data_file.readlines() movements = [Movement(line.strip().split(&#39; &#39;)[0], int(line.strip().split(&#39; &#39;)[1])) for line in lines] display(movements[:3]) display(movements[997:]) . [Movement(direction=&#39;forward&#39;, value=4), Movement(direction=&#39;down&#39;, value=8), Movement(direction=&#39;down&#39;, value=3)] . [Movement(direction=&#39;forward&#39;, value=4), Movement(direction=&#39;forward&#39;, value=4), Movement(direction=&#39;forward&#39;, value=8)] . Ok! We have some data, and we&#39;ve got it formatted in a way that seems reasonable. Essentially, we need to calculate the horizontal and vertical position that the list of movements leaves us in. We will subtract from the vertical when we go up, add when we go down, and add to the horizontal when we move forward. This is a pretty easy set of conditions: . horizontal_position = 0 vertical_position = 0 for movement in movements: if movement.direction == &#39;up&#39;: vertical_position -= movement.value elif movement.direction == &#39;down&#39;: vertical_position += movement.value else: horizontal_position += movement.value display(horizontal_position * vertical_position) . 1648020 . Since the puzzle asks us to give the answer as the multiple of our tracked values, we do. . Success! . But, what about that code? Does it look... a little gross? I think it does. Namely, we&#39;re doing almost the exact same thing for every branch. Can we clean that up? . One approach that I like is to declare the operations in a dictionary: . import operator as ops movement_operation = { &#39;up&#39;: ops.sub, &#39;down&#39;: ops.add, &#39;forward&#39;: ops.add } . Now we can re-write a bit: . horizontal_position = 0 vertical_position = 0 for movement in movements: op = movement_operation[movement.direction] if movement.direction in [&#39;up&#39;, &#39;down&#39;]: vertical_position = op(vertical_position, movement.value) else: horizontal_position = op(horizontal_position, movement.value) display(horizontal_position * vertical_position) . 1648020 . Is this better? It&#39;s a little harder to read, and we have now encoded that vertical_position has to be the thing that both &#39;up&#39; and &#39;down&#39; deal with. If we were to need to change &#39;down&#39; to deal with some other value, this is harder to break apart. On the other hand, the operations are now lifted. If I need to change the operation that is performed for anything, I can do so in one place and be sure that it propogates to all the usage points. That&#39;s pretty cool. . Part 2 . Now we introduce the idea of &quot;aim&quot;. This is fun if you&#39;re a person who has played entirely too much Subnautica because the idea makes sense. In this story, you&#39;re piloting a sub-marine vehicle. So the aim is basically where the nose of the craft is pointed. Adjusting &#39;up&#39; and &#39;down&#39; now affects aim, and only forward changes the values. Pretty easy: . aim = 0 horizontal_position = 0 vertical_position = 0 for movement in movements: op = movement_operation[movement.direction] if movement.direction in [&#39;up&#39;, &#39;down&#39;]: aim = op(aim, movement.value) else: horizontal_position = op(horizontal_position, movement.value) vertical_position = op(vertical_position, (movement.value * aim)) display(horizontal_position * vertical_position) . 1759818555 . Ok, so we solved it, that&#39;s cool... But is this the best way? . We iterate the data (in its cleaned state) just the once. So that&#39;s good, but it still feels like we&#39;re missing something. It seems like the answer being the two values multiplied together means something. . Maybe I&#39;ll figure it out at some point... .",
            "url": "https://pcapel.github.io/thoughts-and-things/advent-of-code/2021/12/02/advent-of-code-2.html",
            "relUrl": "/advent-of-code/2021/12/02/advent-of-code-2.html",
            "date": " • Dec 2, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "Advent of Code 2021 - Day 1",
            "content": "Advent of Code . I have, on every occasion that I have tried, completely failed to follow through on the Advent of Code. This is the year that I change that! . I like Python, so I&#39;m going to be presenting various solutions with Python as a way to play with it again. My goal is to explore the various approaches that one might take, and to think through things from a &quot;first principles&quot; kind of mindset. . So with that said, let&#39;s look at the first day! I&#39;m not going to copy over the text from the problems, but I will state them in my own words. . Part 1 . For the first part, we&#39;re given a list of numbers, and we are looking to determine how many of the numbers are larger than the one before. There&#39;s some story around it, and I appreciate the stories, but this is the gist. . The example is, if we&#39;re given: . 199 200 208 210 200 207 240 269 260 263 . then we would note that: . 199 (N/A - no previous measurement) 200 (increased) 208 (increased) 210 (increased) 200 (decreased) 207 (increased) 240 (increased) 269 (increased) 260 (decreased) 263 (increased) . Ok, so we need to get our input and preferably get it into numeric data types. I&#39;ll start out with a totally naive approach. . with open(&#39;../assets/inputs/aoc/2021/day_1.txt&#39;, &#39;r&#39;) as data_file: data = [int(point.strip()) for point in data_file.readlines()] . We strip the strings and then cast them to integer. This is a dandy way to get a list of values, but now we need to determine how they&#39;re bigger. We could do this in several ways, but the simplest is to iterate the list and make the comparison, storing a count of the values that are, in fact, larger than their predecessor. . count = 0 for i, n in enumerate(data): if n &gt; data[i - 1]: count += 1 print(count) . 1521 . Success! Your data is probably different, but this is the correct answer. We pass the list once, so the complexity here is O(n) on the input. Naively, we would expect that to be the limit for how good this could be. But what about the code itself? . Personally, I don&#39;t like to have state (count) just chilling and getting mutated. That&#39;s a recipe for mixups. . So let&#39;s look at what we&#39;re doing: applying a rule across an iterable and accumulating a result. That sounds an awful lot like a reduce. Trouble is, we don&#39;t really care about the accumulated value in the rule. We only care about the pairwise elements... . If we don&#39;t care about running through the list twice, then we can use a map in the form of a list comprehension to do this pretty effectively: . count = sum([int(n &gt; data[i - 1]) for i, n in enumerate(data)]) print(count) . 1521 . Personally, I like this better. Let&#39;s go ahead and make a function out of it for convenience though. . def count_increase_depths(data): return sum([int(n &gt; data[i - 1]) for i, n in enumerate(data)]) . Part 2 . So part two switches up the approach. We&#39;re going to use the same data, but instead of looking at a single value and it&#39;s predecessor, we want to create a sliding window of sums for sets of 3 values. This is pretty easy to achieve: . windows = [data[i:i + 3] for i in range(len(data))] display(windows[:10]) . [[173, 175, 171], [175, 171, 177], [171, 177, 179], [177, 179, 177], [179, 177, 174], [177, 174, 177], [174, 177, 178], [177, 178, 185], [178, 185, 189], [185, 189, 195]] . Looking at the first ten windows, it looks like we&#39;ve built them correctly, but it always pays to look at the front and the back of a data set. . display(windows[1990:]) . [[7063, 7065, 7066], [7065, 7066, 7071], [7066, 7071, 7079], [7071, 7079, 7092], [7079, 7092, 7102], [7092, 7102, 7118], [7102, 7118, 7115], [7118, 7115, 7121], [7115, 7121], [7121]] . Ah, trailing data from the windows. We can address that by altering the way we build them: . better_windows = [data[i:i + 3] for i in range(len(data) - 2)] display(better_windows[1990:]) . [[7063, 7065, 7066], [7065, 7066, 7071], [7066, 7071, 7079], [7071, 7079, 7092], [7079, 7092, 7102], [7092, 7102, 7118], [7102, 7118, 7115], [7118, 7115, 7121]] . Now, we could generalize this. The window distance itself is related to how many trailing values we end up with. If we defined the window as 4 instead of 3 we&#39;d have gotten 3 trailing values. This could be a helpful function in the future, so let&#39;s go ahead and write it: . def windowed(iterable, window_size): adjust = window_size - 1 windowing_range = range(len(iterable) - adjust) return [iterable[i:i + window_size] for i in windowing_range] display(windowed(data, 3)[1990:]) . [[7063, 7065, 7066], [7065, 7066, 7071], [7066, 7071, 7079], [7071, 7079, 7092], [7079, 7092, 7102], [7092, 7102, 7118], [7102, 7118, 7115], [7118, 7115, 7121]] . I like it! Now we basically need to run the same count algorithm on this, but after summing them. . windowed_data = windowed(data, 3) summed = [sum(window) for window in windowed_data] display(count_increase_depths(summed)) . 1543 . Conclusion . The first day wasn&#39;t a terribly difficult challenge, but it did get me thinking in Python again! I&#39;m really looking forward to doing the rest of the days this year. This should be a lot of fun. .",
            "url": "https://pcapel.github.io/thoughts-and-things/advent-of-code/2021/12/02/advent-of-code-1.html",
            "relUrl": "/advent-of-code/2021/12/02/advent-of-code-1.html",
            "date": " • Dec 2, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Hey! I’m Philip. I’m a guy who writes code and thinks about things. Sometimes it makes sense to write those thoughts down. Sometimes it doesn’t. For your sake, I hope that I have the foresight to know the difference, but I wouldn’t hold my breath. . Sometimes I write code for other people. My opinions and what I write here shouldn’t be thought of as a reflection of the values of those people. These are my own thoughts and musings. . This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://pcapel.github.io/thoughts-and-things/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://pcapel.github.io/thoughts-and-things/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}